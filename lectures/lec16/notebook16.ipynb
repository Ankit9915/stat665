{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras with MNIST\n",
    "Import various modules that we need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/taylor/anaconda3/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset, flatten the images, convert the class labels, and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 28**2).astype('float32') / 255\n",
    "X_test = X_test.reshape(10000, 28**2).astype('float32') / 255\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Basic example \n",
    "Build and compile a basic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(28 * 28,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(10))\n",
    "          \n",
    "sgd = SGD(lr = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss='mse', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model over 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 9s - loss: 0.0496 - acc: 0.7842 - val_loss: 0.0403 - val_acc: 0.8690\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 10s - loss: 0.0427 - acc: 0.8421 - val_loss: 0.0390 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 10s - loss: 0.0415 - acc: 0.8462 - val_loss: 0.0384 - val_acc: 0.8810\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s - loss: 0.0407 - acc: 0.8494 - val_loss: 0.0380 - val_acc: 0.8725\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 10s - loss: 0.0401 - acc: 0.8517 - val_loss: 0.0380 - val_acc: 0.8827\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s - loss: 0.0394 - acc: 0.8548 - val_loss: 0.0362 - val_acc: 0.8788\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s - loss: 0.0386 - acc: 0.8562 - val_loss: 0.0351 - val_acc: 0.8820\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s - loss: 0.0376 - acc: 0.8611 - val_loss: 0.0346 - val_acc: 0.8863\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s - loss: 0.0364 - acc: 0.8651 - val_loss: 0.0328 - val_acc: 0.8892\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s - loss: 0.0351 - acc: 0.8706 - val_loss: 0.0320 - val_acc: 0.8928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x104402e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n",
      "Test classification rate 0.87740\n"
     ]
    }
   ],
   "source": [
    "print(\"Test classification rate %0.05f\" % model.evaluate(X_test, Y_test, show_accuracy=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict classes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>953</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1099</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>802</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>881</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>616</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>866</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0     1    2    3    4    5    6    7    8    9\n",
       "row_0                                                   \n",
       "0      953     0   23    6    0   21   16    5   12   20\n",
       "1        0  1099   25    7   11    9    4   31   13    8\n",
       "2        1     3  802   13    4    4    4   13    5    1\n",
       "3        1     2   24  889    0   83    1    7   20   11\n",
       "4        0     1   17    3  881   16    9   12    9   52\n",
       "5        4     0    0    6    1  616   12    0   16    0\n",
       "6       12     5   39   10   16   25  901    2   16    1\n",
       "7        1     0   23   21    1   17    0  911    5   43\n",
       "8        7    24   72   41   16   79   11    8  866   17\n",
       "9        1     1    7   14   52   22    0   39   12  856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict_classes(X_test)\n",
    "pd.crosstab(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Deeper model with dropout and cross entropy\n",
    "\n",
    "Let's now build a deeper model, with three hidden dense layers and dropout layers. I'll use rectified linear units as they tend to perform better on deep models. I also initilize the nodes using \"glorot_normal\", which uses Gaussian noise scaled by the sum of the inputs plus outputs from the node. Notice that we do not need to give an input shape to any layers other than the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(28 * 28,), init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 26s - loss: 0.5702 - acc: 0.8184 - val_loss: 0.1335 - val_acc: 0.9617\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 30s - loss: 0.2693 - acc: 0.9241 - val_loss: 0.1062 - val_acc: 0.9683\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 29s - loss: 0.2157 - acc: 0.9382 - val_loss: 0.0988 - val_acc: 0.9713\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 30s - loss: 0.1790 - acc: 0.9486 - val_loss: 0.0867 - val_acc: 0.9758\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 29s - loss: 0.1613 - acc: 0.9538 - val_loss: 0.0743 - val_acc: 0.9783\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 30s - loss: 0.1463 - acc: 0.9575 - val_loss: 0.0731 - val_acc: 0.9787\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 29s - loss: 0.1341 - acc: 0.9618 - val_loss: 0.0689 - val_acc: 0.9797\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 30s - loss: 0.1260 - acc: 0.9632 - val_loss: 0.0715 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 30s - loss: 0.1190 - acc: 0.9663 - val_loss: 0.0649 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 31s - loss: 0.1135 - acc: 0.9679 - val_loss: 0.0730 - val_acc: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x104402a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGD(lr = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n",
      "Test classification rate 0.97730\n",
      "10000/10000 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>953</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1099</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>802</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>881</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>616</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>866</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0     1    2    3    4    5    6    7    8    9\n",
       "row_0                                                   \n",
       "0      953     0   23    6    0   21   16    5   12   20\n",
       "1        0  1099   25    7   11    9    4   31   13    8\n",
       "2        1     3  802   13    4    4    4   13    5    1\n",
       "3        1     2   24  889    0   83    1    7   20   11\n",
       "4        0     1   17    3  881   16    9   12    9   52\n",
       "5        4     0    0    6    1  616   12    0   16    0\n",
       "6       12     5   39   10   16   25  901    2   16    1\n",
       "7        1     0   23   21    1   17    0  911    5   43\n",
       "8        7    24   72   41   16   79   11    8  866   17\n",
       "9        1     1    7   14   52   22    0   39   12  856"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test classification rate %0.05f\" % model.evaluate(X_test, Y_test, show_accuracy=True)[1])\n",
    "fy_hat = model.predict_classes(X_test)\n",
    "pd.crosstab(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_wrong = [im for im in zip(X_test,y_hat,y_test) if im[1] != im[2]]\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, val in enumerate(test_wrong[:100]):\n",
    "    plt.subplot(10, 10, ind + 1)\n",
    "    im = 1 - val[0].reshape((28,28))\n",
    "    axis(\"off\")\n",
    "    plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Small model: Visualizing weights\n",
    "Now, I want to make a model that has only a small number of hidden nodes in each layer. We may then have a chance of actually visualizing the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(28 * 28,), init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification rate on the validation set is not nearly as predictive, but it is still not too bad overall. A model object contains a list of its layers. The weights are easy to pull out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.layers) # list of the layers\n",
    "print(model.layers[0].get_weights()[0].shape) # the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first set of weights will be given as weights the same size as the input space. Notice how "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = model.layers[0].get_weights()[0]\n",
    "\n",
    "for ind, val in enumerate(W1.T):\n",
    "    plt.figure(figsize=(3, 3), frameon=False)\n",
    "    im = val.reshape((28,28))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(im, cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer of weights will be given as a single 16x16 matrix of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W2 = model.layers[3].get_weights()[0]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "im = W2.reshape((16,16))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(im, cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Further tweaks: weights and alternative optimizers\n",
    "Just to show off a few more tweaks, we'll run one final model. Here we use weights and an alternative to vanillia stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape=(28 * 28,), init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\",W_regularizer=l2(0.1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\",W_regularizer=l2(0.1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=5,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
